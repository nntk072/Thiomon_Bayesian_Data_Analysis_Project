Environment setup

```{r}
rm(list = ls())
# setwd("/notebooks/bda2024/Bayes_project")
setwd("c:/Users/nguye/OneDrive - Aalto University/University/First year/Project/Bayes_project/")
SEED = 42
if (!require(readr)) {
    install.packages("readr")
    library(readr)
}

if (!require(rstan)) {
    install.packages("rstan")
    library(rstan)
}
if (!require(loo)) {
    install.packages("loo")
    library(loo)
}
if (!require(gridExtra)) {
    install.packages("gridExtra")
    library(gridExtra)
}
if (!require(grid)) {
    install.packages("grid")
    library(grid)
}
if (!require(rmarkdown)) {
    install.packages("rmarkdown")
    library(rmarkdown)
}


if (!require(tidybayes)) {
    install.packages("tidybayes")
    library(tidybayes)
}
if (!require(brms)) {
    install.packages("brms")
    library(brms)
}
if (!require(metadat)) {
  install.packages("metadat")
  library(metadat)
}
# if(!require(cmdstanr)){
#     install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
#     library(cmdstanr)
# }
# cmdstan_installed <- function(){
#   res <- try(out <- cmdstanr::cmdstan_path(), silent = TRUE)
#   !inherits(res, "try-error")
# }
# if(!cmdstan_installed()){
#     install_cmdstan()
# }
if(!require(ggplot2)){
    install.packages("ggplot2")
    library(ggplot2)
}
ggplot2::theme_set(theme_minimal(base_size = 14))
if(!require(bayesplot)){
    install.packages("bayesplot")
    library(bayesplot)
}
if(!require(posterior)){
    install.packages("posterior")
    library(posterior)
}
if (!require(priorsense)) {
  install.packages("priorsense")
  library(priorsense)
}
if (!require(tibble)) {
  install.packages("tibble")
  library(tibble)
}
if (!require(RColorBrewer)) {
  install.packages("RColorBrewer")
  library(RColorBrewer)
}
if (!require(dplyr)) {
  install.packages("dplyr")
  library(dplyr)
}
if (!require(tinytable)) {
  install.packages("tinytable")
  library(tinytable)
}
if (!require(pROC)) {
  install.packages("pROC")
  library(pROC)
}
if (!require(caret)) {
  install.packages("caret")
  library(caret)
}
options(tinytable_format_num_fmt = "significant_cell", tinytable_format_digits = 2, tinytable_tt_digits=2)
```


Process the data

```{r}
# Load the saved data frames
load("thiomon_source_data.rda")
load("thiomon_test_data.rda")

source_data <- store_data

# Specify the number of rows to sample
NUM_OF_SAMPLES <- 4500

# Randomly sample rows from the data frame
train_data <- source_data[sample(nrow(source_data), NUM_OF_SAMPLES), ]

# View the sampled data frame
print(train_data)

# Extract the 'remission' column
train_data2 <- train_data["remission"]
```

```{r}
ref_thiomon_formulae <- bf(remission ~ 0 + hgb + log_siirat + hct + deRitisRatio, family = "bernoulli")
thiomon_priors_default_priors <- get_prior(ref_thiomon_formulae, data = train_data)
thiomon_set_priors_informative <- c(
  prior(
    normal(14.65,1.275),
    class = "b",
    coef = "hgb"
  ),
  
  prior(
    normal(7,1),
    class = "b",
    coef = "log_siirat"
  ),
  

  prior(
    normal(43,3.5),
    class = "b",
    coef = "hct"
  ),  
  prior(
    normal(1.05,0.175), 
    class = "b", 
    coef = "deRitisRatio"
    )
  
)

thiomon_data_model <- brm(
    formula = ref_thiomon_formulae,
    prior = thiomon_set_priors_informative,
    data = train_data,
    save_pars = save_pars(all = TRUE),
    iter = 2000,
    warmup = 1000,
    chains = 4,                           # Number of chains
    control = list(
      adapt_delta = 0.95,                 # Increase acceptance rate target if needed
      max_treedepth = 15                 # Increase the tree depth if needed
    ) 
)
# Calculate predicted probabilities on training data
train_predicted_probs_separate <- posterior_predict(thiomon_data_model, newdata = train_data, draws = 4000, allow_new_levels = TRUE)
train_mean_probs_separate <- colMeans(train_predicted_probs_separate)

# Find optimal threshold using ROC curve on training data
train_roc_curve_separate <- roc(train_data$remission, train_mean_probs_separate)
optimal_threshold_separate <- coords(train_roc_curve_separate, "best", ret = "threshold")

# Predict on test data
predicted_probs_separate <- posterior_predict(thiomon_data_model, newdata = test_data, draws = 1000, allow_new_levels = TRUE)
mean_probs_separate <- colMeans(predicted_probs_separate)

# ROC Curve
roc_curve_separate <- roc(test_data$remission, mean_probs_separate)
plot(roc_curve_separate, main = "ROC Curve for Separate Model")

# Confusion Matrix
predicted_classes_separate <- ifelse(mean_probs_separate >= optimal_threshold_separate$threshold, 1, 0)
conf_matrix_separate <- confusionMatrix(as.factor(predicted_classes_separate), as.factor(test_data$remission))
print(conf_matrix_separate)

#Report model summary, Rhat, ESS, convergence statistics etc.,
summary(thiomon_data_model)

#Check EPLD LOO
loo(thiomon_data_model)

#Check if chains converge
mcmc_trace(thiomon_data_model, pars=c("b_hgb", "b_log_siirat", "b_hct", "b_deRitisRatio")) + scale_colour_manual(values=c("#000000", "#E69F00", "#56B4E9", "#009E73"))

#Autocorrelation function?

#Make PP checks
pp_check(thiomon_data_model, type='dens_overlay', ndraws=200)
pp_check(thiomon_data_model, type='loo_pit_qq', ndraws=1000)
pp_check(thiomon_data_model, type='pit_ecdf', ndraws=1000)

#Test for prior sensitivity
model_draws <- as_draws_df(thiomon_data_model)

#Prior sensitivity is not there thanks to informative priors
powerscale_plot_dens(model_draws, fit=thiomon_data_model,
                     help_text=FALSE)

#Also the values look good!
powerscale_sensitivity(model_draws, fit=thiomon_data_model) |>
  tt()

#Summarize the draws
model_draws |> subset_draws(variable=c('lprior','lp__'), exclude=TRUE) |> summarise_draws() |> tt()

as_draws_df(model_draws) |> mcmc_areas(pars=c('b_hgb', 'b_log_siirat', 'b_hct', 'b_deRitisRatio'))
```


```{r}
ref_thiomon_formulae <- bf(remission ~ 0 + hgb + log_siirat + hct + deRitisRatio + (1|age) , family = "bernoulli")
hierarchical_data_model_1 <- brm(
    formula = ref_thiomon_formulae,
    prior = thiomon_set_priors_informative,
    data = train_data,
    save_pars = save_pars(all = TRUE),
    iter = 2000,
    warmup = 1000,
    chains = 4,                           # Number of chains
    control = list(
      adapt_delta = 0.95,                 # Increase acceptance rate target if needed
      max_treedepth = 15                 # Increase the tree depth if needed
    ) 
)
# Calculate predicted probabilities on training data
train_predicted_probs_hierarchical_1 <- posterior_predict(hierarchical_data_model_1, newdata = train_data, draws = 4000, allow_new_levels = TRUE)
train_mean_probs_hierarchical_1 <- colMeans(train_predicted_probs_hierarchical_1)

# Find optimal threshold using ROC curve on training data
train_roc_curve_hierarchical_1 <- roc(train_data$remission, train_mean_probs_hierarchical_1)
optimal_threshold_hierarchical_1 <- coords(train_roc_curve_hierarchical_1, "best", ret = "threshold")

# Predict on test data
predicted_probs_hierarchical_1 <- posterior_predict(hierarchical_data_model_1, newdata = test_data, draws = 1000, allow_new_levels = TRUE)
mean_probs_hierarchical_1 <- colMeans(predicted_probs_hierarchical_1)

# ROC Curve
roc_curve_hierarchical_1 <- roc(test_data$remission, mean_probs_hierarchical_1)
plot(roc_curve_hierarchical_1, main = "ROC Curve for First Model")

# Confusion Matrix
predicted_classes_hierarchical_1 <- ifelse(mean_probs_hierarchical_1 >= optimal_threshold_hierarchical_1$threshold, 1, 0)
conf_matrix_hierarchical_1 <- confusionMatrix(as.factor(predicted_classes_hierarchical_1), as.factor(test_data$remission))
print(conf_matrix_hierarchical_1)

# Report model summary, Rhat, ESS, convergence statistics etc.
summary(hierarchical_data_model_1)

# Check EPLD LOO
loo(hierarchical_data_model_1)

# Check if chains converge
mcmc_trace(hierarchical_data_model_1, pars=c("b_hgb", "b_log_siirat", "b_hct", "b_deRitisRatio")) + scale_colour_manual(values=c("#000000", "#E69F00", "#56B4E9", "#009E73"))

# Autocorrelation function?

# Make PP checks
pp_check(hierarchical_data_model_1, type='dens_overlay', ndraws=200)
pp_check(hierarchical_data_model_1, type='loo_pit_qq', ndraws=1000)
pp_check(hierarchical_data_model_1, type='pit_ecdf', ndraws=1000)

# Test for prior sensitivity
model_draws_1 <- as_draws_df(hierarchical_data_model_1)

# Prior sensitivity is not there thanks to informative priors
powerscale_plot_dens(model_draws_1, fit=hierarchical_data_model_1, help_text=FALSE)

# Also the values look good!
powerscale_sensitivity(model_draws_1, fit=hierarchical_data_model_1) |>
  tt()

# Summarize the draws
model_draws_1 |> subset_draws(variable=c('lprior','lp__'), exclude=TRUE) |> summarise_draws() |> tt()

as_draws_df(model_draws_1) |> mcmc_areas(pars=c('b_hgb', 'b_log_siirat', 'b_hct', 'b_deRitisRatio'))
```

```{r}
ref_thiomon_formulae <- bf(remission ~ 0 + hgb + log_siirat + hct + deRitisRatio + (1 + 1|age), family = "bernoulli")
thiomon_priors_default_priors <- get_prior(ref_thiomon_formulae, data = train_data)

hierarchical_data_model_2 <- brm(
    formula = ref_thiomon_formulae,
    prior = thiomon_set_priors_informative,
    data = train_data,
    save_pars = save_pars(all = TRUE),
    iter = 2000,
    warmup = 1000,
    chains = 4,
    control = list(
      adapt_delta = 0.95,
      max_treedepth = 15
    )
)
# Calculate predicted probabilities on training data
train_predicted_probs_hierarchical_2 <- posterior_predict(hierarchical_data_model_2, newdata = train_data, draws = 4000, allow_new_levels = TRUE)
train_mean_probs_hierarchical_2 <- colMeans(train_predicted_probs_hierarchical_2)

# Find optimal threshold using ROC curve on training data
train_roc_curve_hierarchical_2 <- roc(train_data$remission, train_mean_probs_hierarchical_2)
optimal_threshold_hierarchical_2 <- coords(train_roc_curve_hierarchical_2, "best", ret = "threshold")

# Predict on test data
predicted_probs_hierarchical_2 <- posterior_predict(hierarchical_data_model_2, newdata = test_data, draws = 1000, allow_new_levels = TRUE)
mean_probs_hierarchical_2 <- colMeans(predicted_probs_hierarchical_2)

# ROC Curve
roc_curve_hierarchical_2 <- roc(test_data$remission, mean_probs_hierarchical_2)
plot(roc_curve_hierarchical_2, main = "ROC Curve for Second Model")

# Confusion Matrix
predicted_classes_hierarchical_2 <- ifelse(mean_probs_hierarchical_2 >= optimal_threshold_hierarchical_2$threshold, 1, 0)
conf_matrix_hierarchical_2 <- confusionMatrix(as.factor(predicted_classes_hierarchical_2), as.factor(test_data$remission))
print(conf_matrix_hierarchical_2)

# Check EPLD LOO
loo(hierarchical_data_model_2)

# Check if chains converge
mcmc_trace(hierarchical_data_model_2, pars=c("b_hgb", "b_log_siirat", "b_hct", "b_deRitisRatio")) + scale_colour_manual(values=c("#000000", "#E69F00", "#56B4E9", "#009E73"))

# Autocorrelation function?

# Make PP checks
pp_check(hierarchical_data_model_2, type='dens_overlay', ndraws=200)
pp_check(hierarchical_data_model_2, type='loo_pit_qq', ndraws=1000)
pp_check(hierarchical_data_model_2, type='pit_ecdf', ndraws=1000)

# Test for prior sensitivity
model_draws_2 <- as_draws_df(hierarchical_data_model_2)

# Prior sensitivity is not there thanks to informative priors
powerscale_plot_dens(model_draws_2, fit=hierarchical_data_model_2, help_text=FALSE)

# Also the values look good!
powerscale_sensitivity(model_draws_2, fit=hierarchical_data_model_2) |>
  tt()

# Summarize the draws
model_draws_2 |> subset_draws(variable=c('lprior','lp__'), exclude=TRUE) |> summarise_draws() |> tt()

as_draws_df(model_draws_2) |> mcmc_areas(pars=c('b_hgb', 'b_log_siirat', 'b_hct', 'b_deRitisRatio'))
```

```{r}
ref_thiomon_formulae <- bf(remission ~ 1 + hgb + log_siirat + hct + deRitisRatio + (1|age), family = "bernoulli")
thiomon_priors_default_priors <- get_prior(ref_thiomon_formulae, data = train_data)

hierarchical_data_model_3 <- brm(
    formula = ref_thiomon_formulae,
    prior = thiomon_set_priors_informative,
    data = train_data,
    save_pars = save_pars(all = TRUE),
    iter = 2000,
    warmup = 1000,
    chains = 4,
    control = list(
      adapt_delta = 0.95,
      max_treedepth = 15
    )
)
# Calculate predicted probabilities on training data
train_predicted_probs_hierarchical_3 <- posterior_predict(hierarchical_data_model_3, newdata = train_data, draws = 4000, allow_new_levels = TRUE)
train_mean_probs_hierarchical_3 <- colMeans(train_predicted_probs_hierarchical_3)

# Find optimal threshold using ROC curve on training data
train_roc_curve_hierarchical_3 <- roc(train_data$remission, train_mean_probs_hierarchical_3)
optimal_threshold_hierarchical_3 <- coords(train_roc_curve_hierarchical_3, "best", ret = "threshold")

# Predict on test data
predicted_probs_hierarchical_3 <- posterior_predict(hierarchical_data_model_3, newdata = test_data, draws = 1000, allow_new_levels = TRUE)
mean_probs_hierarchical_3 <- colMeans(predicted_probs_hierarchical_3)

# ROC Curve
roc_curve_hierarchical_3 <- roc(test_data$remission, mean_probs_hierarchical_3)
plot(roc_curve_hierarchical_3, main = "ROC Curve for Third Model")

# Confusion Matrix
predicted_classes_hierarchical_3 <- ifelse(mean_probs_hierarchical_3 >= optimal_threshold_hierarchical_3$threshold, 1, 0)
conf_matrix_hierarchical_3 <- confusionMatrix(as.factor(predicted_classes_hierarchical_3), as.factor(test_data$remission))
print(conf_matrix_hierarchical_3)

# Report model summary, Rhat, ESS, convergence statistics etc.
summary(hierarchical_data_model_3)

# Check EPLD LOO
loo(hierarchical_data_model_3)

# Check if chains converge
mcmc_trace(hierarchical_data_model_3, pars=c("b_hgb", "b_log_siirat", "b_hct", "b_deRitisRatio")) + scale_colour_manual(values=c("#000000", "#E69F00", "#56B4E9", "#009E73"))

# Autocorrelation function?

# Make PP checks
pp_check(hierarchical_data_model_3, type='dens_overlay', ndraws=200)
pp_check(hierarchical_data_model_3, type='loo_pit_qq', ndraws=1000)
pp_check(hierarchical_data_model_3, type='pit_ecdf', ndraws=1000)

# Test for prior sensitivity
model_draws_3 <- as_draws_df(hierarchical_data_model_3)

# Prior sensitivity is not there thanks to informative priors
powerscale_plot_dens(model_draws_3, fit=hierarchical_data_model_3, help_text=FALSE)

# Also the values look good!
powerscale_sensitivity(model_draws_3, fit=hierarchical_data_model_3) |>
  tt()

# Summarize the draws
model_draws_3 |> subset_draws(variable=c('lprior','lp__'), exclude=TRUE) |> summarise_draws() |> tt()

as_draws_df(model_draws_3) |> mcmc_areas(pars=c('b_hgb', 'b_log_siirat', 'b_hct', 'b_deRitisRatio'))
```


```{r}
library(pROC)
library(ggplot2)

# Function to interpolate and smooth ROC curve with jitter
interpolate_smooth_roc_jitter <- function(roc_curve, n = 100, jitter_amount = 1e-5) {
  roc_smooth <- smooth(roc_curve)
  fpr <- seq(0, 1, length.out = n)
  tpr <- approx(roc_smooth$specificities + runif(length(roc_smooth$specificities), -jitter_amount, jitter_amount), 
                roc_smooth$sensitivities, xout = fpr)$y
  data.frame(fpr = fpr, tpr = tpr)
}

# Calculate and interpolate ROC curves with jitter
roc_seperate_train <- interpolate_smooth_roc_jitter(train_roc_curve_seperate)
roc_seperate_test <- interpolate_smooth_roc_jitter(test_roc_curve_seperate)
roc_hierarchical_1_train <- interpolate_smooth_roc_jitter(train_roc_curve_hierarchical_1)
roc_hierarchical_1_test <- interpolate_smooth_roc_jitter(test_roc_curve_hierarchical_1)
roc_hierarchical_2_train <- interpolate_smooth_roc_jitter(train_roc_curve_hierarchical_2)
roc_hierarchical_2_test <- interpolate_smooth_roc_jitter(roc_curve_hierarchical_2)
roc_hierarchical_3_train <- interpolate_smooth_roc_jitter(train_roc_curve_hierarchical_3)
roc_hierarchical_3_test <- interpolate_smooth_roc_jitter(roc_curve_hierarchical_3)

# Calculate AUC values
auc_seperate_train <- auc(train_roc_curve_seperate)
auc_seperate_test <- auc(test_roc_curve_seperate)
auc_hierarchical_1_train <- auc(train_roc_curve_hierarchical_1)
auc_hierarchical_1_test <- auc(test_roc_curve_hierarchical_1)
auc_hierarchical_2_train <- auc(train_roc_curve_hierarchical_2)
auc_hierarchical_2_test <- auc(roc_curve_hierarchical_2)
auc_hierarchical_3_train <- auc(train_roc_curve_hierarchical_3)
auc_hierarchical_3_test <- auc(roc_curve_hierarchical_3)

# Combine ROC curves into one data frame
# roc_data <- rbind(
#   data.frame(roc_logistic_train, model = paste("Logistic Train (AUC =", round(auc_logistic_train, 2), ")")),
#   data.frame(roc_logistic_test, model = paste("Logistic Test (AUC =", round(auc_logistic_test, 2), ")")),
#   data.frame(roc_simple_train, model = paste("Simple Train (AUC =", round(auc_simple_train, 2), ")")),
#   data.frame(roc_simple_test, model = paste("Simple Test (AUC =", round(auc_simple_test, 2), ")")),
#   data.frame(roc_hierarchical_train, model = paste("Hierarchical Train (AUC =", round(auc_hierarchical_train, 2), ")")),
#   data.frame(roc_hierarchical_test, model = paste("Hierarchical Test (AUC =", round(auc_hierarchical_test, 2), ")"))
# )

# Combine ROC curves into one data frame
roc_data <- rbind(
  data.frame(roc_seperate_train, model = paste("Seperate Train (AUC =", round(auc_seperate_train, 2), ")
  "),
  data.frame(roc_seperate_test, model = paste("Seperate Test (AUC =", round(auc_seperate_test, 2), ")
  "),
  data.frame(roc_hierarchical_1_train, model = paste("Hierarchical 1 Train (AUC =", round(auc_hierarchical_1_train, 2), ")
  "),
  data.frame(roc_hierarchical_1_test, model = paste("Hierarchical 1 Test (AUC =", round(auc_hierarchical_1_test, 2), ")
  "),
  data.frame(roc_hierarchical_2_train, model = paste("Hierarchical 2 Train (AUC =", round(auc_hierarchical_2_train, 2), ")
  "),
  data.frame(roc_hierarchical_2_test, model = paste("Hierarchical 2 Test (AUC =", round(auc_hierarchical_2_test, 2), ")
  "),
  data.frame(roc_hierarchical_3_train, model = paste("Hierarchical 3 Train (AUC =", round(auc_hierarchical_3_train, 2), ")
  "),
  data.frame(roc_hierarchical_3_test, model = paste("Hierarchical 3 Test (AUC =", round(auc_hierarchical_3_test, 2), ")
  ")
)
# Plot all ROC curves in one plot
ggplot(roc_data, aes(x = fpr, y = tpr, color = model)) +
  geom_line() +
  labs(title = "ROC Curves for Different Models", x = "False Positive Rate", y = "True Positive Rate") +
  theme_minimal() +
  theme(legend.position = "bottom")
```
