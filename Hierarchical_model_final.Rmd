Environment setup

```{r}
rm(list = ls())
setwd("/notebooks/bda2024/Bayes_project")
#setwd("c:/Users/nguye/OneDrive - Aalto University/University/First year/Project/Bayes_project/")
SEED = 42
if (!require(rstan)) {
    install.packages("rstan")
    library(rstan)
}
if (!require(loo)) {
    install.packages("loo")
    library(loo)
}
if (!require(gridExtra)) {
    install.packages("gridExtra")
    library(gridExtra)
}
if (!require(grid)) {
    install.packages("grid")
    library(grid)
}
if (!require(rmarkdown)) {
    install.packages("rmarkdown")
    library(rmarkdown)
}
if (!require(tidybayes)) {
    install.packages("tidybayes")
    library(tidybayes)
}
if (!require(brms)) {
    install.packages("brms")
    library(brms)
}
if (!require(metadat)) {
  install.packages("metadat")
  library(metadat)
}
if(!require(cmdstanr)){
   install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
   library(cmdstanr)
}
cmdstan_installed <- function(){
 res <- try(out <- cmdstanr::cmdstan_path(), silent = TRUE)
 !inherits(res, "try-error")
}
if(!cmdstan_installed()){
   install_cmdstan()
}
if(!require(ggplot2)){
    install.packages("ggplot2")
    library(ggplot2)
}
ggplot2::theme_set(theme_minimal(base_size = 14))
if(!require(bayesplot)){
    install.packages("bayesplot")
    library(bayesplot)
}
if(!require(posterior)){
    install.packages("posterior")
    library(posterior)
}
if (!require(priorsense)) {
  install.packages("priorsense")
  library(priorsense)
}
if (!require(tibble)) {
  install.packages("tibble")
  library(tibble)
}
if (!require(RColorBrewer)) {
  install.packages("RColorBrewer")
  library(RColorBrewer)
}
if (!require(dplyr)) {
  install.packages("dplyr")
  library(dplyr)
}
if (!require(tinytable)) {
  install.packages("tinytable")
  library(tinytable)
}
if (!require(pROC)) {
  install.packages("pROC")
  library(pROC)
}
if (!require(caret)) {
  install.packages("caret")
  library(caret)
}
options(tinytable_format_num_fmt = "significant_cell", tinytable_format_digits = 2, tinytable_tt_digits=2)
```

Data setup

```{r}
#Loading the data
load("thiomon.rda")

#Cleanup entries that have NaN values or values that are not populated
thiomon <- na.omit(thiomon)
```

Correlation Matrix for observation between retransmission and the target variable

```{r}
correlation_matrix <- cor(thiomon)
remission_correlation <- abs(correlation_matrix[, 'remission'])
remission_correlation <- sort(remission_correlation, decreasing = TRUE)
#print(remission_correlation)
df <- data.frame(remission_correlation)
options(digits = 1)
print(df)
```

Filtering the variables and pre-processing the data

```{r}

# From the original paper top-7 recommended parameters from CBC
#c("hgb", "lymph_percent", "hct","neut_percent", "plt", "alb", "ast")]

#Process the data set with some additional processing
source_data <- thiomon

# Set the age of the patient, granularity years
source_data["age"] <- round(thiomon$days_of_life / 365, digits = 0)

# Simple predictor check: mean corpuscular volume [MCV] and reductions in the white blood cell count [WBC], MCV/WBC ratio
source_data["mcv_wbc_rat"] <- round(thiomon$mcv / thiomon$wbc, digits = 0)

# The systemic immune-inflammation index (SII), defined as neutrophils Ã— platelets / lymphocytes
source_data["sii_rat"] <- round((source_data$plt * source_data$neut_percent) / source_data$lymph_percent, digits = 0)
source_data["log_siirat"] <- log(source_data["sii_rat"])

#The AST/ALT ratio or De Ritis ratio is the ratio between the concentrations of two enzymes, aspartate transaminase (AST) and alanine transaminase, aka alanine aminotransferase (ALT), in the blood of a human
source_data["deRitisRatio"] <- round(source_data$ast / source_data$alt, digits = 2)
  
# Group the age into 9 groups 0-10, 11-20, 21-30, 31-40, 41-50, 51-60, 61-70, 71-80, 81-90
source_data["age_group"] <- cut(source_data$age, breaks = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90), labels = c("5", "15", "25", "35", "45", "55", "65", "75", "85"))
# Group hct into 10 groups, by splitting into 10 ranges (max - min) / 10
source_data["hct_group"] <- cut(source_data$hct, breaks = seq(min(source_data$hct), max(source_data$hct), length.out = 11), labels = c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10"))

#Split data for model fitting and testing separately
store_data <- source_data[1:4500, ]
test_data <- source_data[4501:nrow(source_data), ]

# Save the data file so we don't have to process everytime
save(store_data, file = "thiomon_source_data.rda")
save(test_data, file = "thiomon_test_data.rda")
```

Process the data

```{r}
# Load the saved data frames
load("thiomon_source_data.rda")
load("thiomon_test_data.rda")

source_data <- store_data

# Specify the number of rows to sample
NUM_OF_SAMPLES <- 4500

# Randomly sample rows from the data frame
train_data <- source_data[sample(nrow(source_data), NUM_OF_SAMPLES), ]

# View the sampled data frame
print(train_data)

# Extract the 'remission' column
train_data2 <- train_data["remission"]
```

```{r}
ref_thiomon_formulae <- bf(remission ~ 0 + hgb + log_siirat + hct + deRitisRatio, family = "bernoulli")
thiomon_priors_default_priors <- get_prior(ref_thiomon_formulae, data = train_data)

thiomon_set_priors_informative <- c(
  prior(
    normal(10,5),
    class = "b",
    coef = "hgb"
  ),
  
  prior(
    normal(7,1),
    class = "b",
    coef = "log_siirat"
  ),
  
  prior(
    normal(1,1),
    class = "b",
    coef = "deRitisRatio"
  ),

  prior(
    normal(35,3),
    class = "b",
    coef = "hct"
  )  
)

thiomon_data_model_1 <- brm(
    formula = ref_thiomon_formulae,
    prior = thiomon_set_priors_informative,
    data = train_data,
    save_pars = save_pars(all = TRUE),
    iter = 2000,
    warmup = 1000,
    chains = 4,                           # Number of chains
    control = list(
      adapt_delta = 0.8,                 # Increase acceptance rate target if needed
      max_treedepth = 10                 # Increase the tree depth if needed
    ),
    threads = threading(2), cores = 8, backend = "cmdstanr",
)
# Calculate predicted probabilities on training data
train_predicted_probs_separate_1 <- posterior_predict(thiomon_data_model_1, newdata = train_data, draws = 4000, allow_new_levels = TRUE)
train_mean_probs_separate_1 <- colMeans(train_predicted_probs_separate_1)

# Find optimal threshold using ROC curve on training data
train_roc_curve_separate_1 <- roc(train_data$remission, train_mean_probs_separate_1)
optimal_threshold_separate_1 <- coords(train_roc_curve_separate_1, "best", ret = "threshold")

# Predict on test data
predicted_probs_separate_1 <- posterior_predict(thiomon_data_model_1, newdata = test_data, draws = 1000, allow_new_levels = TRUE)
mean_probs_separate_1 <- colMeans(predicted_probs_separate_1)

# ROC Curve
roc_curve_separate_1 <- roc(test_data$remission, mean_probs_separate_1)
plot(roc_curve_separate_1, main = "ROC Curve for Separate Model")

# Confusion Matrix
predicted_classes_separate_1 <- ifelse(mean_probs_separate_1 >= optimal_threshold_separate_1$threshold, 1, 0)
conf_matrix_separate_1 <- confusionMatrix(as.factor(predicted_classes_separate_1), as.factor(test_data$remission))
print(conf_matrix_separate_1)

#Report model summary, Rhat, ESS, convergence statistics etc.,
summary(thiomon_data_model_1)

#Check EPLD LOO
loo(thiomon_data_model_1)

#Check if chains converge
mcmc_trace(thiomon_data_model_1, pars=c("b_hgb", "b_log_siirat", "b_hct", "b_deRitisRatio")) + scale_colour_manual(values=c("#000000", "#E69F00", "#56B4E9", "#009E73"))

#Autocorrelation function?

#Make PP checks
pp_check(thiomon_data_model_1, type='dens_overlay', ndraws=200)
pp_check(thiomon_data_model_1, type='loo_pit_qq', ndraws=1000)
pp_check(thiomon_data_model_1, type='pit_ecdf', ndraws=1000)

#Test for prior sensitivity
model_draws <- as_draws_df(thiomon_data_model_1)

#Prior sensitivity is not there thanks to informative priors
powerscale_plot_dens(model_draws, fit=thiomon_data_model_1,
                     help_text=FALSE)

#Also the values look good!
powerscale_sensitivity(model_draws, fit=thiomon_data_model_1) |> tt()

#Summarize the draws
model_draws |> subset_draws(variable=c('lprior','lp__'), exclude=TRUE) |> summarise_draws() |> tt()

as_draws_df(model_draws) |> mcmc_areas(pars=c('b_hgb', 'b_log_siirat', 'b_hct', 'b_deRitisRatio'))
```

```{r}
ref_thiomon_formulae <- bf(remission ~ 0 + hgb + hct + wbc + mpv + mchc, family = "bernoulli") # 65.8
thiomon_priors_default_priors <- get_prior(ref_thiomon_formulae, data = train_data)

thiomon_set_priors_informative <- c(
  prior(
    normal(10,5),
    class = "b",
    coef = "hgb"
  ),
  
  prior(
    normal(8,2),
    class = "b",
    coef = "wbc"
  ),
  
  prior(
    normal(34,1),
    class = "b",
    coef = "mchc"
  ),

  prior(
    normal(35,3),
    class = "b",
    coef = "hct"
  ),
  
  prior(
    normal(8,1),
    class = "b",
    coef = "mpv"
  ) 
)

thiomon_data_model_2 <- brm(
    formula = ref_thiomon_formulae,
    prior = thiomon_set_priors_informative,
    data = train_data,
    save_pars = save_pars(all = TRUE),
    iter = 2000,
    warmup = 1000,
    chains = 4,                           # Number of chains
    control = list(
      adapt_delta = 0.8,                 # Increase acceptance rate target if needed
      max_treedepth = 10                 # Increase the tree depth if needed
    ),
    threads = threading(2), cores = 8, backend = "cmdstanr",
)
# Calculate predicted probabilities on training data
train_predicted_probs_separate_2 <- posterior_predict(thiomon_data_model_2, newdata = train_data, draws = 4000, allow_new_levels = TRUE)
train_mean_probs_separate_2 <- colMeans(train_predicted_probs_separate_2)

# Find optimal threshold using ROC curve on training data
train_roc_curve_separate_2 <- roc(train_data$remission, train_mean_probs_separate_2)
optimal_threshold_separate_2 <- coords(train_roc_curve_separate_2, "best", ret = "threshold")

# Predict on test data
predicted_probs_separate_2 <- posterior_predict(thiomon_data_model_2, newdata = test_data, draws = 1000, allow_new_levels = TRUE)
mean_probs_separate_2 <- colMeans(predicted_probs_separate_2)

# ROC Curve
roc_curve_separate_2 <- roc(test_data$remission, mean_probs_separate_2)
plot(roc_curve_separate_2, main = "ROC Curve for Separate Model")

# Confusion Matrix
predicted_classes_separate_2 <- ifelse(mean_probs_separate_2 >= optimal_threshold_separate_2$threshold, 1, 0)
conf_matrix_separate_2 <- confusionMatrix(as.factor(predicted_classes_separate_2), as.factor(test_data$remission))
print(conf_matrix_separate_2)

#Report model summary, Rhat, ESS, convergence statistics etc.,
summary(thiomon_data_model_2)

#Check EPLD LOO
loo(thiomon_data_model_2)
ref_thiomon_formulae <- bf(remission ~ hgb + hct + wbc + mpv + mchc, family = "bernoulli") # 64.9
#Check if chains converge
mcmc_trace(thiomon_data_model_2, pars=c("b_hgb", "b_hct", "b_wbc", "b_mpv", "b_mchc")) + scale_colour_manual(values=c("#000000", "#E69F00", "#56B4E9", "#009E73", "red"))

#Autocorrelation function?

#Make PP checks
pp_check(thiomon_data_model_2, type='dens_overlay', ndraws=200)
pp_check(thiomon_data_model_2, type='loo_pit_qq', ndraws=1000)
pp_check(thiomon_data_model_2, type='pit_ecdf', ndraws=1000)

#Test for prior sensitivity
model_draws <- as_draws_df(thiomon_data_model_2)

#Prior sensitivity is not there thanks to informative priors
powerscale_plot_dens(model_draws, fit=thiomon_data_model_2,
                     help_text=FALSE)

#Also the values look good!
powerscale_sensitivity(model_draws, fit=thiomon_data_model_2) |> tt()

#Summarize the draws
model_draws |> subset_draws(variable=c('lprior','lp__'), exclude=TRUE) |> summarise_draws() |> tt()

as_draws_df(model_draws) |> mcmc_areas(pars=c("b_hgb", "b_hct", "b_wbc", "b_mpv", "b_mchc"))
```

```{r}
#Focus for today
ref_thiomon_formulae <- bf(remission ~ 0 + hgb + hct + wbc + mpv + mchc + (1|hct), family = "bernoulli") # 65.5
thiomon_set_priors_informative <- c(
  prior(
    normal(10,5),
    class = "b",
    coef = "hgb"
  ),
  
  prior(
    normal(8,2),
    class = "b",
    coef = "wbc"
  ),
  
  prior(
    normal(34,1),
    class = "b",
    coef = "mchc"
  ),

  prior(
    normal(35,3),
    class = "b",
    coef = "hct"
  ),
  
  prior(
    normal(8,1),
    class = "b",
    coef = "mpv"
  ) 
)
hierarchical_data_model_1 <- brm(
    formula = ref_thiomon_formulae,
    prior = thiomon_set_priors_informative,
    data = train_data,
    save_pars = save_pars(all = TRUE),
    iter = 2000,
    warmup = 1000,
    chains = 4,                           # Number of chains
    control = list(
      adapt_delta = 0.8,                 # Increase acceptance rate target if needed
      max_treedepth = 10                 # Increase the tree depth if needed
    ),
    threads = threading(2), cores = 8, backend = "cmdstanr", 
)
```

```{r}
# Calculate predicted probabilities on training data
train_predicted_probs_hierarchical_1 <- posterior_predict(hierarchical_data_model_1, newdata = train_data, draws = 4000, allow_new_levels = TRUE)
train_mean_probs_hierarchical_1 <- colMeans(train_predicted_probs_hierarchical_1)

# Find optimal threshold using ROC curve on training data
train_roc_curve_hierarchical_1 <- roc(train_data$remission, train_mean_probs_hierarchical_1)
optimal_threshold_hierarchical_1 <- coords(train_roc_curve_hierarchical_1, "best", ret = "threshold")

# Predict on test data
predicted_probs_hierarchical_1 <- posterior_predict(hierarchical_data_model_1, newdata = test_data, draws = 1000, allow_new_levels = TRUE)
mean_probs_hierarchical_1 <- colMeans(predicted_probs_hierarchical_1)

# ROC Curve
roc_curve_hierarchical_1 <- roc(test_data$remission, mean_probs_hierarchical_1)
plot(roc_curve_hierarchical_1, main = "ROC Curve for First Model")

# Confusion Matrix
predicted_classes_hierarchical_1 <- ifelse(mean_probs_hierarchical_1 >= optimal_threshold_hierarchical_1$threshold, 1, 0)
conf_matrix_hierarchical_1 <- confusionMatrix(as.factor(predicted_classes_hierarchical_1), as.factor(test_data$remission))
print(conf_matrix_hierarchical_1)

# Report model summary, Rhat, ESS, convergence statistics etc.
summary(hierarchical_data_model_1)

# Check EPLD LOO
loo(hierarchical_data_model_1)

# Check if chains converge
mcmc_trace(hierarchical_data_model_1, pars=c("b_hgb", "b_hct", "b_wbc", "b_mpv", "b_mchc")) + scale_colour_manual(values=c("#000000", "#E69F00", "#56B4E9", "#009E73","red"))

# Autocorrelation function?

# Make PP checks
pp_check(hierarchical_data_model_1, type='dens_overlay', ndraws=200)
pp_check(hierarchical_data_model_1, type='loo_pit_qq', ndraws=1000)
pp_check(hierarchical_data_model_1, type='pit_ecdf', ndraws=1000)

# Test for prior sensitivity
model_draws_1 <- as_draws_df(hierarchical_data_model_1)

# Prior sensitivity is not there thanks to informative priors
# powerscale_plot_dens(model_draws_1, fit=hierarchical_data_model_1, help_text=FALSE)

# Also the values look good!
powerscale_sensitivity(model_draws_1, fit=hierarchical_data_model_1) |>
  tt()

# Summarize the draws
model_draws_1 |> subset_draws(variable=c('lprior','lp__'), exclude=TRUE) |> summarise_draws() |> tt()

as_draws_df(model_draws_1) |> mcmc_areas(pars=c("b_hgb", "b_hct", "b_wbc", "b_mpv", "b_mchc"))
```

```{r}
ref_thiomon_formulae <- bf(remission ~ 0 + hgb + hct + wbc + mpv + mchc + (1|hct_group), family = "bernoulli")
thiomon_priors_default_priors <- get_prior(ref_thiomon_formulae, data = train_data)
thiomon_set_priors_informative <- c(
  prior(
    normal(10,5),
    class = "b",
    coef = "hgb"
  ),
  
  prior(
    normal(8,2),
    class = "b",
    coef = "wbc"
  ),
  
  prior(
    normal(34,1),
    class = "b",
    coef = "mchc"
  ),

  prior(
    normal(35,3),
    class = "b",
    coef = "hct"
  ),
  
  prior(
    normal(8,1),
    class = "b",
    coef = "mpv"
  ) 
)
hierarchical_data_model_2 <- brm(
    formula = ref_thiomon_formulae,
    prior = thiomon_set_priors_informative,
    data = train_data,
    save_pars = save_pars(all = TRUE),
    iter = 2000,
    warmup = 1000,
    chains = 4,
    control = list(
      adapt_delta = 0.8,
      max_treedepth = 10
    ),
    threads = threading(2), cores = 8, backend = "cmdstanr",   
)
# Calculate predicted probabilities on training data
train_predicted_probs_hierarchical_2 <- posterior_predict(hierarchical_data_model_2, newdata = train_data, draws = 4000, allow_new_levels = TRUE)
train_mean_probs_hierarchical_2 <- colMeans(train_predicted_probs_hierarchical_2)

# Find optimal threshold using ROC curve on training data
train_roc_curve_hierarchical_2 <- roc(train_data$remission, train_mean_probs_hierarchical_2)
optimal_threshold_hierarchical_2 <- coords(train_roc_curve_hierarchical_2, "best", ret = "threshold")

# Predict on test data
predicted_probs_hierarchical_2 <- posterior_predict(hierarchical_data_model_2, newdata = test_data, draws = 1000, allow_new_levels = TRUE)
mean_probs_hierarchical_2 <- colMeans(predicted_probs_hierarchical_2)

# ROC Curve
roc_curve_hierarchical_2 <- roc(test_data$remission, mean_probs_hierarchical_2)
plot(roc_curve_hierarchical_2, main = "ROC Curve for Second Model")

# Confusion Matrix
predicted_classes_hierarchical_2 <- ifelse(mean_probs_hierarchical_2 >= optimal_threshold_hierarchical_2$threshold, 1, 0)
conf_matrix_hierarchical_2 <- confusionMatrix(as.factor(predicted_classes_hierarchical_2), as.factor(test_data$remission))
print(conf_matrix_hierarchical_2)

# Check EPLD LOO
loo(hierarchical_data_model_2)

# Check if chains converge
mcmc_trace(hierarchical_data_model_1, pars=c("b_hgb", "b_hct", "b_wbc", "b_mpv", "b_mchc")) + scale_colour_manual(values=c("#000000", "#E69F00", "#56B4E9", "#009E73","red"))

# Autocorrelation function?

# Make PP checks
pp_check(hierarchical_data_model_2, type='dens_overlay', ndraws=200)
pp_check(hierarchical_data_model_2, type='loo_pit_qq', ndraws=1000)
pp_check(hierarchical_data_model_2, type='pit_ecdf', ndraws=1000)

# Test for prior sensitivity
model_draws_2 <- as_draws_df(hierarchical_data_model_2)

# Prior sensitivity is not there thanks to informative priors
powerscale_plot_dens(model_draws_2, fit=hierarchical_data_model_2, help_text=FALSE)

# Also the values look good!
powerscale_sensitivity(model_draws_2, fit=hierarchical_data_model_2) |>
  tt()

# Summarize the draws
model_draws_2 |> subset_draws(variable=c('lprior','lp__'), exclude=TRUE) |> summarise_draws() |> tt()

as_draws_df(model_draws_2) |> mcmc_areas(pars=c("b_hgb", "b_hct", "b_wbc", "b_mpv", "b_mchc"))
```

```{r}
# ref_thiomon_formulae <- bf(remission ~ 0 + hgb + log_siirat + deRitisRatio + + (1|hct) + (1|mono_percent) + (1|baso_percent) + (1|eos_percent), family = "bernoulli")
ref_thiomon_formulae <- bf(remission ~ 0 + hgb + log_siirat + deRitisRatio + hct + (1|hct), family = "bernoulli")
thiomon_set_priors_informative <- c(
  prior(
    normal(10,5),
    class = "b",
    coef = "hgb"
  ),
  
  prior(
    normal(7,1),
    class = "b",
    coef = "log_siirat"
  ),
  
  prior(
    normal(1,1),
    class = "b",
    coef = "deRitisRatio"
  ),

  prior(
    normal(35,3),
    class = "b",
    coef = "hct"
  )  
)
hierarchical_data_model_3 <- brm(
    formula = ref_thiomon_formulae,
    prior = thiomon_set_priors_informative,
    data = train_data,
    save_pars = save_pars(all = TRUE),
    iter = 2000,
    warmup = 1000,
    chains = 4,                           # Number of chains
    control = list(
      adapt_delta = 0.8,                 # Increase acceptance rate target if needed
      max_treedepth = 10               # Increase the tree depth if needed
    ),
    threads = threading(2), cores = 8, backend = "cmdstanr",
    # save_cmdstan_config = TRUE            # Save CmdStan configuration
    # opencl = opencl(c(0, 0))
)

# Calculate predicted probabilities on training data
train_predicted_probs_hierarchical_3 <- posterior_predict(hierarchical_data_model_3, newdata = train_data, draws = 4000, allow_new_levels = TRUE)
train_mean_probs_hierarchical_3 <- colMeans(train_predicted_probs_hierarchical_3)

# Find optimal threshold using ROC curve on training data
train_roc_curve_hierarchical_3 <- roc(train_data$remission, train_mean_probs_hierarchical_3)
optimal_threshold_hierarchical_3 <- coords(train_roc_curve_hierarchical_3, "best", ret = "threshold")

# Predict on test data
predicted_probs_hierarchical_3 <- posterior_predict(hierarchical_data_model_3, newdata = test_data, draws = 1000, allow_new_levels = TRUE)
mean_probs_hierarchical_3 <- colMeans(predicted_probs_hierarchical_3)

# ROC Curve
roc_curve_hierarchical_3 <- roc(test_data$remission, mean_probs_hierarchical_3)
plot(roc_curve_hierarchical_3, main = "ROC Curve for Third Model")

# Confusion Matrix
predicted_classes_hierarchical_3 <- ifelse(mean_probs_hierarchical_3 >= optimal_threshold_hierarchical_3$threshold, 1, 0)
conf_matrix_hierarchical_3 <- confusionMatrix(as.factor(predicted_classes_hierarchical_3), as.factor(test_data$remission))
print(conf_matrix_hierarchical_3)

# Report model summary, Rhat, ESS, convergence statistics etc.
summary(hierarchical_data_model_3)

# Check EPLD LOO
loo(hierarchical_data_model_3)

# Check if chains converge
mcmc_trace(hierarchical_data_model_3, pars=c("b_hgb", "b_log_siirat", "b_hct", "b_deRitisRatio")) + scale_colour_manual(values=c("#000000", "#E69F00", "#56B4E9", "#009E73"))

# Autocorrelation function?

# Make PP checks
pp_check(hierarchical_data_model_3, type='dens_overlay', ndraws=200)
pp_check(hierarchical_data_model_3, type='loo_pit_qq', ndraws=1000)
pp_check(hierarchical_data_model_3, type='pit_ecdf', ndraws=1000)

# Test for prior sensitivity
model_draws_3 <- as_draws_df(hierarchical_data_model_3)

# Prior sensitivity is not there thanks to informative priors
# powerscale_plot_dens(model_draws_3, fit=hierarchical_data_model_3, help_text=FALSE)

# Also the values look good!
powerscale_sensitivity(model_draws_3, fit=hierarchical_data_model_3) |>
  tt()

# Summarize the draws
model_draws_3 |> subset_draws(variable=c('lprior','lp__'), exclude=TRUE) |> summarise_draws() |> tt()

as_draws_df(model_draws_3) |> mcmc_areas(pars=c('b_hgb', 'b_log_siirat', 'b_hct', 'b_deRitisRatio'))
```

```{r}
ref_thiomon_formulae <- bf(remission ~ 0 + hgb + log_siirat + deRitisRatio + hct + (1| hct_group), family = "bernoulli")
thiomon_set_priors_informative <- c(
  prior(
    normal(10,5),
    class = "b",
    coef = "hgb"
  ),
  
  prior(
    normal(7,1),
    class = "b",
    coef = "log_siirat"
  ),
  
  prior(
    normal(1,1),
    class = "b",
    coef = "deRitisRatio"
  ),

  prior(
    normal(35,3),
    class = "b",
    coef = "hct"
  )  
)
hierarchical_data_model_4 <- brm(
    formula = ref_thiomon_formulae,
    prior = thiomon_set_priors_informative,
    data = train_data,
    save_pars = save_pars(all = TRUE),
    iter = 2000,
    warmup = 1000,
    chains = 4,
    control = list(
      adapt_delta = 0.8,
      max_treedepth = 10
    ),
    threads = threading(2), cores = 8, backend = "cmdstanr",
)
# Calculate predicted probabilities on training data
train_predicted_probs_hierarchical_4 <- posterior_predict(hierarchical_data_model_4, newdata = train_data, draws = 4000, allow_new_levels = TRUE)
train_mean_probs_hierarchical_4 <- colMeans(train_predicted_probs_hierarchical_4)

# Find optimal threshold using ROC curve on training data
train_roc_curve_hierarchical_4 <- roc(train_data$remission, train_mean_probs_hierarchical_4)
optimal_threshold_hierarchical_4 <- coords(train_roc_curve_hierarchical_4, "best", ret = "threshold")

# Predict on test data
predicted_probs_hierarchical_4 <- posterior_predict(hierarchical_data_model_4, newdata = test_data, draws = 1000, allow_new_levels = TRUE)
mean_probs_hierarchical_4 <- colMeans(predicted_probs_hierarchical_4)

# ROC Curve
roc_curve_hierarchical_4 <- roc(test_data$remission, mean_probs_hierarchical_4)
plot(roc_curve_hierarchical_4, main = "ROC Curve for Second Model")

# Confusion Matrix
predicted_classes_hierarchical_4 <- ifelse(mean_probs_hierarchical_4 >= optimal_threshold_hierarchical_4$threshold, 1, 0)
conf_matrix_hierarchical_4 <- confusionMatrix(as.factor(predicted_classes_hierarchical_4), as.factor(test_data$remission))
print(conf_matrix_hierarchical_4)

# Check EPLD LOO
loo(hierarchical_data_model_4)

# Check if chains converge
mcmc_trace(hierarchical_data_model_4, pars=c("b_hgb", "b_log_siirat", "b_hct", "b_deRitisRatio")) + scale_colour_manual(values=c("#000000", "#E69F00", "#56B4E9", "#009E73"))

# Autocorrelation function?

# Make PP checks
pp_check(hierarchical_data_model_4, type='dens_overlay', ndraws=200)
pp_check(hierarchical_data_model_4, type='loo_pit_qq', ndraws=1000)
pp_check(hierarchical_data_model_4, type='pit_ecdf', ndraws=1000)

# Test for prior sensitivity
model_draws_4 <- as_draws_df(hierarchical_data_model_4)

# Prior sensitivity is not there thanks to informative priors
powerscale_plot_dens(model_draws_4, fit=hierarchical_data_model_4, help_text=FALSE)

# Also the values look good!
powerscale_sensitivity(model_draws_4, fit=hierarchical_data_model_4) |>
  tt()

# Summarize the draws
model_draws_4 |> subset_draws(variable=c('lprior','lp__'), exclude=TRUE) |> summarise_draws() |> tt()

as_draws_df(model_draws_4) |> mcmc_areas(pars=c('b_hgb', 'b_log_siirat', 'b_hct', 'b_deRitisRatio'))
```

```{r}
library(pROC)
library(ggplot2)

# Function to interpolate and smooth ROC curve with jitter
interpolate_smooth_roc_jitter <- function(roc_curve, n = 100, jitter_amount = 1e-5) {
  roc_smooth <- smooth(roc_curve)
  fpr <- seq(0, 1, length.out = n)
  tpr <- approx(roc_smooth$specificities + runif(length(roc_smooth$specificities), -jitter_amount, jitter_amount), 
                roc_smooth$sensitivities, xout = fpr)$y
  data.frame(fpr = fpr, tpr = tpr)
}

# Calculate and interpolate ROC curves with jitter
roc_separate_1_train <- interpolate_smooth_roc_jitter(train_roc_curve_separate_1)
roc_separate_1_test <- interpolate_smooth_roc_jitter(roc_curve_separate_1)
roc_separate_2_train <- interpolate_smooth_roc_jitter(train_roc_curve_separate_2)
roc_separate_2_test <- interpolate_smooth_roc_jitter(roc_curve_separate_2)
roc_hierarchical_1_train <- interpolate_smooth_roc_jitter(train_roc_curve_hierarchical_1)
roc_hierarchical_1_test <- interpolate_smooth_roc_jitter(roc_curve_hierarchical_1)
roc_hierarchical_2_train <- interpolate_smooth_roc_jitter(train_roc_curve_hierarchical_2)
roc_hierarchical_2_test <- interpolate_smooth_roc_jitter(roc_curve_hierarchical_2)
roc_hierarchical_3_train <- interpolate_smooth_roc_jitter(train_roc_curve_hierarchical_3)
roc_hierarchical_3_test <- interpolate_smooth_roc_jitter(roc_curve_hierarchical_3)
roc_hierarchical_4_train <- interpolate_smooth_roc_jitter(train_roc_curve_hierarchical_4)
roc_hierarchical_4_test <- interpolate_smooth_roc_jitter(roc_curve_hierarchical_4)

# Calculate AUC values
auc_separate_1_train <- auc(train_roc_curve_separate_1)
auc_separate_1_test <- auc(roc_curve_separate_1)
auc_separate_2_train <- auc(train_roc_curve_separate_2)
auc_separate_2_test <- auc(roc_curve_separate_2)
auc_hierarchical_1_train <- auc(train_roc_curve_hierarchical_1)
auc_hierarchical_1_test <- auc(roc_curve_hierarchical_1)
auc_hierarchical_2_train <- auc(train_roc_curve_hierarchical_2)
auc_hierarchical_2_test <- auc(roc_curve_hierarchical_2)
auc_hierarchical_3_train <- auc(train_roc_curve_hierarchical_3)
auc_hierarchical_3_test <- auc(roc_curve_hierarchical_3)
auc_hierarchical_4_train <- auc(train_roc_curve_hierarchical_4)
auc_hierarchical_4_test <- auc(roc_curve_hierarchical_4)
# Combine ROC curves into one data frame
# roc_data <- rbind(
#   data.frame(roc_logistic_train, model = paste("Logistic Train (AUC =", round(auc_logistic_train, 2), ")")),
#   data.frame(roc_logistic_test, model = paste("Logistic Test (AUC =", round(auc_logistic_test, 2), ")")),
#   data.frame(roc_simple_train, model = paste("Simple Train (AUC =", round(auc_simple_train, 2), ")")),
#   data.frame(roc_simple_test, model = paste("Simple Test (AUC =", round(auc_simple_test, 2), ")")),
#   data.frame(roc_hierarchical_train, model = paste("Hierarchical Train (AUC =", round(auc_hierarchical_train, 2), ")")),
#   data.frame(roc_hierarchical_test, model = paste("Hierarchical Test (AUC =", round(auc_hierarchical_test, 2), ")"))
# )

# Combine ROC curves into one data frame
roc_data <- rbind(
  data.frame(roc_separate_1_train, model = paste("separate Train (AUC =", round(auc_separate_1_train, 4), ")")),
  data.frame(roc_separate_1_test, model = paste("separate Test (AUC =", round(auc_separate_1_test, 4), ")")),
  data.frame(roc_separate_2_train, model = paste("separate Train (AUC =", round(auc_separate_2_train, 4), ")")),
  data.frame(roc_separate_2_test, model = paste("separate Test (AUC =", round(auc_separate_2_test, 4), ")")),
  data.frame(roc_hierarchical_1_train, model = paste("Hierarchical 1 Train (AUC =", round(auc_hierarchical_1_train, 4), ")")),
  data.frame(roc_hierarchical_1_test, model = paste("Hierarchical 1 Test (AUC =", round(auc_hierarchical_1_test, 4), ")")),
  data.frame(roc_hierarchical_2_train, model = paste("Hierarchical 2 Train (AUC =", round(auc_hierarchical_2_train, 4), ")")),
  data.frame(roc_hierarchical_2_test, model = paste("Hierarchical 2 Test (AUC =", round(auc_hierarchical_2_test, 4), ")")),
  data.frame(roc_hierarchical_3_train, model = paste("Hierarchical 3 Train (AUC =", round(auc_hierarchical_3_train, 4), ")")),
  data.frame(roc_hierarchical_3_test, model = paste("Hierarchical 3 Test (AUC =", round(auc_hierarchical_3_test, 4), ")")),
  data.frame(roc_hierarchical_4_train, model = paste("Hierarchical 4 Train (AUC =", round(auc_hierarchical_4_train, 4), ")")),
  data.frame(roc_hierarchical_4_test, model = paste("Hierarchical 4 Test (AUC =", round(auc_hierarchical_4_test, 4), ")"))
)
# Plot all ROC curves in one plot
ggplot(roc_data, aes(x = fpr, y = tpr, color = model)) +
  geom_line() +
  labs(title = "ROC Curves for Different Models", x = "False Positive Rate", y = "True Positive Rate") +
  theme_minimal() +
```

```{theme(legend.position = "bottom")}
```

```{r}
library(e1071)
library(caret)

model_svm <- svm(remission ~ 0 + days_of_life + wbc + hgb + hct + plt + rbc + mcv + mch + mchc + rdw + mpv + neut_percent + lymph_percent + mono_percent + eos_percent + baso_percent + sod + pot + chlor + co2 + un + creat + gluc + cal + prot + alb + ast + alt + alk + tbil, data = thiomon)

pred_probs <- predict(model_svm, type = "response")

pred_classes <- ifelse(pred_probs > 0.5, 1, 0)

table(predicted = pred_classes, actual = thiomon$remission)

confusionMatrix(factor(pred_classes), factor(thiomon$remission))
```

```{r}
model_glm <- glm(remission ~ 0 + days_of_life + wbc + hgb + hct + plt + rbc + mcv + mch + mchc + rdw + mpv + neut_percent + lymph_percent + mono_percent + eos_percent + baso_percent + sod + pot + chlor + co2 + un + creat + gluc + cal + prot + alb + ast + alt + alk + tbil, data = thiomon)

pred_probs <- predict(model_glm, type = "response")

pred_classes <- ifelse(pred_probs > 0.5, 1, 0)

table(predicted = pred_classes, actual = thiomon$remission)

confusionMatrix(factor(pred_classes), factor(thiomon$remission))
```

```{r}
install.packages("nnet")
library(nnet)

# Example: Training a neural network
model <- nnet(remission ~ days_of_life + wbc + hgb + hct + plt + rbc + mcv + mch + mchc + rdw + mpv + neut_percent + lymph_percent + mono_percent + eos_percent + baso_percent + sod + pot + chlor + co2 + un + creat + gluc + cal + prot + alb + ast + alt + alk + tbil, data = thiomon, size = 20,    # Number of hidden units 
maxit = 100)  # For classification

# Make predictions
predictions <- predict(model, thiomon)

# Convert to class labels
pred_labels <- ifelse(predictions[, 1] > 0.5, 1, 0)

# Confusion matrix (for evaluation)
table(Predicted = pred_labels, Actual = thiomon$remission)

confusionMatrix(factor(pred_classes), factor(thiomon$remission))
```
