Environment setup

```{r}
rm(list = ls())
setwd("c:/Users/nguye/OneDrive - Aalto University/University/First year/Project/Bayes_project/")
# setwd("/notebooks/bda2024/Bayes_project")
SEED = 42
if(!require(nnet)) {
  install.packages("nnet")
  library(nnet)
}
if (!require(rstan)) {
    install.packages("rstan")
    library(rstan)
}

if (!require(loo)) {
    install.packages("loo")
    library(loo)
}

if (!require(gridExtra)) {
    install.packages("gridExtra")
    library(gridExtra)
}

if (!require(grid)) {
    install.packages("grid")
    library(grid)
}
if (!require(rmarkdown)) {
    install.packages("rmarkdown")
    library(rmarkdown)
}

if (!require(tidybayes)) {
    install.packages("tidybayes")
    library(tidybayes)
}

if (!require(brms)) {
    install.packages("brms")
    library(brms)
}

if (!require(metadat)) {
  install.packages("metadat")
  library(metadat)
}

if(!require(cmdstanr)){
    install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
    library(cmdstanr)
}

cmdstan_installed <- function(){
  res <- try(out <- cmdstanr::cmdstan_path(), silent = TRUE)
  !inherits(res, "try-error")
}

if(!cmdstan_installed()){
    install_cmdstan()
}

if(!require(ggplot2)){
    install.packages("ggplot2")
    library(ggplot2)
}

ggplot2::theme_set(theme_minimal(base_size = 14))
if(!require(bayesplot)){
    install.packages("bayesplot")
    library(bayesplot)
}

if(!require(posterior)){
    install.packages("posterior")
    library(posterior)
}

if (!require(priorsense)) {
  install.packages("priorsense")
  library(priorsense)
}

if (!require(tibble)) {
  install.packages("tibble")
  library(tibble)
}

if (!require(RColorBrewer)) {
  install.packages("RColorBrewer")
  library(RColorBrewer)
}

if (!require(dplyr)) {
  install.packages("dplyr")
  library(dplyr)
}

if (!require(tinytable)) {
  install.packages("tinytable")
  library(tinytable)
}

if (!require(pROC)) {
  install.packages("pROC")
  library(pROC)
}

if (!require(caret)) {
  install.packages("caret")
  library(caret)
}

if(!require(fitdistrplus)){
    install.packages("fitdistrplus", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
    library(fitdistrplus)
}

options(tinytable_format_num_fmt = "significant_cell", tinytable_format_digits = 2, tinytable_tt_digits=2)
```

Data setup

```{r}
#Loading the data
load("thiomon.rda")

#Cleanup entries that have NaN values or values that are not populated
thiomon <- na.omit(thiomon)
```

Correlation Matrix for observation between retransmission and the target variable

```{r}
correlation_matrix <- cor(thiomon)
remission_correlation <- abs(correlation_matrix[, 'remission'])
remission_correlation <- sort(remission_correlation, decreasing = TRUE)
#print(remission_correlation)
df <- data.frame(remission_correlation)
options(digits = 1)
print(df)
```

```{r}
# From the original paper top-7 recommended parameters from CBC
#c("hgb", "lymph_percent", "hct","neut_percent", "plt", "alb", "ast")]

#Process the data set with some additional processing
source_data <- thiomon

# Set the age of the patient, granularity years
source_data["age"] <- round(thiomon$days_of_life / 365, digits = 0)

# Simple predictor check: mean corpuscular volume [MCV] and reductions in the white blood cell count [WBC], MCV/WBC ratio
source_data["mcv_wbc_rat"] <- round(thiomon$mcv / thiomon$wbc, digits = 0)

# The systemic immune-inflammation index (SII), defined as neutrophils Ã— platelets / lymphocytes
source_data["sii_rat"] <- round((source_data$plt * source_data$neut_percent) / source_data$lymph_percent, digits = 0)
source_data["log_siirat"] <- log(source_data["sii_rat"])

#The AST/ALT ratio or De Ritis ratio is the ratio between the concentrations of two enzymes, aspartate transaminase (AST) and alanine transaminase, aka alanine aminotransferase (ALT), in the blood of a human
source_data["deRitisRatio"] <- round(source_data$ast / source_data$alt, digits = 2)

source_data["age_group"] <- floor(source_data["age"]/10) + 1

source_data["hbghctrat"] = round(thiomon$hgb/thiomon$hct,2)

# Group hct into 10 groups, by splitting into 10 ranges (max - min) / 10
#source_data["hbghctrat"] <- cut(source_data$hbghctrat, breaks = seq(min(source_data$hbghctrat), max(source_data$hbghctrat), length.out = 11), labels = c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10"))
source_data["hbghctrat"] <- cut(source_data$hbghctrat, breaks = seq(min(source_data$hbghctrat), max(source_data$hbghctrat), length.out = 6), labels = c("1", "2", "3", "4", "5"))

source_data["hbghctrat"] <- as.character(source_data$hbghctrat)

source_data <- na.omit(source_data)
#Split data for model fitting and testing separately
train_data <- source_data[1:4500, ]
test_data <- source_data[4501:nrow(source_data), ]

# Save the data file so we don't have to process everytime
save(train_data, file = "thiomon_train_data.rda")
save(test_data, file = "thiomon_test_data.rda")
```

```{r}
# Sample a subset of the 4500 rows to improve computation time
NUM_OF_SAMPLES <- 4500
train_data <- source_data[sample(nrow(source_data), NUM_OF_SAMPLES), ]

# View the sampled data frame if needed
#print(train_data, n=20)
```

```{r}
#Purely pooled model
ref_thiomon_formulae_pooled <- bf(remission ~ 1, family = "bernoulli")

thiomon_priors_default_priors_pooled <- get_prior(ref_thiomon_formulae_pooled, data = train_data)

thiomon_data_model_pooled <- brm(
    formula = ref_thiomon_formulae_pooled,
    prior = thiomon_priors_default_priors_pooled,
    data = train_data,
    save_pars = save_pars(all = TRUE),
    iter = 2000,
    warmup = 1000,
    chains = 4,                           # Number of chains
    control = list(
      adapt_delta = 0.8,                 # Increase acceptance rate target if needed
      max_treedepth = 20                 # Increase the tree depth if needed
    ),
    threads = threading(2), cores = 8, backend = "cmdstanr"
)
```

`{print(df,nrows=32)}`

Filtering the variables and pre-processing the data

```{r}
#Task 2: Use the top 7 blood parameters and improvise on the model
#BRMS formula using the top 7
#thiomon_formulae_3 <- bf(remission ~ 0 + hgb + lymph_percent + hct + neut_percent + plt + alb + ast, family = "bernoulli")

#One improvement is to combine the different blood parameters according to medical science. SII and deRitisRatio are 2 such covariates which are recogonized. Reducing the number of covariates not only is computationally efficient but the search for informative priors is easier
#ref_thiomon_formulae <- bf(remission ~ 0 + hgb + log_siirat + hct + deRitisRatio, family = "bernoulli")

#ref_thiomon_formulae <- bf(remission ~ 0  + lymph_percent + hct + neut_percent + plt + alb + ast + alk + mono_percent + rdw + mch + wbc + hgb + age + mcv + eos_percent + alt + mpv + baso_percent + gluc + mchc + tbil + cal + prot + un + pot + chlor + co2 + sod + creat, family = "bernoulli")

#thiomon_formulae_3 <- bf(remission ~ 0 + hgb + lymph_percent + hct + neut_percent + plt + alb + ast, family = "bernoulli")

#Default priors are flat and created at least two issues
#Issue 1 - Accuracy of the model is not optimal (61%)
#Issue 2 - Prior sensitivity checks fail as flat priors have infinite k-hat values
#There was no issue with improper posterior with flat priors

ref_thiomon_formulae_separate <- bf(remission ~ 0 + hgb + hct + hbghctrat, family = "bernoulli")

thiomon_priors_default_priors_separate <- get_prior(ref_thiomon_formulae_separate, data = train_data)

#Values of the parameters and their legal values were checked and also tools like fitdist were used

#Normal distribution works well for all parameters except SII wherein instead of SII, log(SII) is uniformly distributed
#Informative priors are set based on the distributions of the parameters themselves after plotting with e.g., mcmc_hist()

#All parameters of model saved for e.g., for LOO and moment matching if needed

(thiomon_set_priors_informative_separate <- c(
  prior(
    normal(13,5),
    class = "b",
    coef = "hgb"
  ),

  prior(
    normal(35,5),
    class = "b",
    coef = "hct"
  ) 
))

thiomon_data_model_separate <- brm(
    formula = ref_thiomon_formulae_separate,
    prior = thiomon_priors_default_priors_separate,
    data = train_data,
    iter = 2000,
    warmup = 1000,
    chains = 4,                           # Number of chains
    control = list(
      adapt_delta = 0.8,                 # Increase acceptance rate target if needed
      max_treedepth = 20                 # Increase the tree depth if needed
    ),
    threads = threading(2), cores = 8, backend = "cmdstanr"
)
```

Process the data

```{r}
ref_thiomon_formulae_hier <- bf(remission ~ 0 + hgb + hct + (1 | hbghctrat), family = "bernoulli")

thiomon_priors_default_priors_hier <- get_prior(ref_thiomon_formulae_hier, data = train_data)

(thiomon_set_priors_informative_hier <- c(
  prior(
    normal(13,5),
    class = "b",
    coef = "hgb"
  ),
  
  prior(
    normal(35,5),
    class = "b",
    coef = "hct"
  ) 
))

thiomon_data_model_hier <- brm(
    formula = ref_thiomon_formulae_hier,
    prior = thiomon_priors_default_priors_hier,
    data = train_data,
    iter = 2000,
    warmup = 1000,
    chains = 4,                           # Number of chains
    control = list(
      adapt_delta = 0.8,                 # Increase acceptance rate target if needed
      max_treedepth = 20                 # Increase the tree depth if needed
    ),
    threads = threading(2), cores = 8, backend = "cmdstanr"
)

```






```{r}
#Task 0 - Inapplicability of pooled model
#Why pooled model cannot be used here? With pooled model there is one single global intercept which from the practical point does not make sense as there is no way in which any blood parameter can take the value 0 in real life for humans. We can only experiment with separate models.

#Continue investigations with separate model
#Task 1: Testing the predictive power of a bayesian model using all the parameters indicated in the research paper
#The baseline formula uses 100% of the blood parameters
#thiomon_baseline <- bf(remission ~ 0 + hgb + lymph_percent + hct + neut_percent + plt + alb + ast + alk + mono_percent + rdw + mch + wbc + age + mcv + eos_percent + alt + mpv + baso_percent + gluc + mchc + tbil + cal + prot + un + pot + chlor + co2 + sod + creat, family = "bernoulli")

#The priors are default ones
#thiomon_priors <- get_prior(thiomon_formulae, data = train_data)

#Purpose of Task 1 is to numerically assess the predictive power of the baseline bayesian model fitting all blood parameters to a bionomial distribution with logit as the outcome to predict the remission status of the disease
#The model predicts with 66% accuracy (79% in the paper with a machine learning model)
#For future work section
#Improve the accuracy of the model by using informative priors,combine

# Calculate predicted probabilities on training data
train_predicted_probs_pooled <- posterior_predict(thiomon_data_model_pooled, newdata = train_data, draws = 4000, allow_new_levels = TRUE)
train_mean_probs_pooled <- colMeans(train_predicted_probs_pooled)

# Find optimal threshold using ROC curve on training data
train_roc_curve_pooled <- roc(train_data$remission, train_mean_probs_pooled)
optimal_threshold_pooled <- coords(train_roc_curve_pooled, "best", ret = "threshold")

# Predict on test data
predicted_probs_pooled <- posterior_predict(thiomon_data_model_pooled, newdata = test_data, draws = 1000, allow_new_levels = TRUE)
mean_probs_pooled <- colMeans(predicted_probs_pooled)

# ROC Curve
roc_curve_pooled <- roc(test_data$remission, mean_probs_pooled)
plot(roc_curve_pooled, main = "ROC Curve for Separate Model")

# Confusion Matrix
predicted_classes_pooled <- ifelse(mean_probs_pooled >= optimal_threshold_pooled$threshold, 1, 0)
conf_matrix_pooled <- confusionMatrix(as.factor(predicted_classes_pooled), as.factor(test_data$remission))
print(conf_matrix_pooled)

#Report model summary, Rhat, ESS, convergence statistics etc.,
summary(thiomon_data_model_pooled)

#Check EPLD LOO
loo(thiomon_data_model_pooled)

#Make PP checks
pp_check(thiomon_data_model_pooled, type='dens_overlay', ndraws=200)
pp_check(thiomon_data_model_pooled, type='loo_pit_qq', ndraws=1000)
pp_check(thiomon_data_model_pooled, type='pit_ecdf', ndraws=1000)

#Test for prior sensitivity
model_draws <- as_draws_df(thiomon_data_model_pooled)

#Prior sensitivity is not there thanks to informative priors
powerscale_plot_dens(model_draws, fit=thiomon_data_model_pooled,
                     help_text=FALSE)

#Also the values look good!
powerscale_sensitivity(model_draws, fit=thiomon_data_model_pooled) |> tt()

#Summarize the draws
model_draws |> subset_draws(variable=c('lprior','lp__'), exclude=TRUE) |> summarise_draws() |> tt()
```

```{r}
# Calculate predicted probabilities on training data
train_predicted_probs_separate <- posterior_predict(thiomon_data_model_separate, newdata = train_data, draws = 4000, allow_new_levels = TRUE)
train_mean_probs_separate <- colMeans(train_predicted_probs_separate)

# Find optimal threshold using ROC curve on training data
train_roc_curve_separate <- roc(train_data$remission, train_mean_probs_separate)
optimal_threshold_separate <- coords(train_roc_curve_separate, "best", ret = "threshold")

# Predict on test data
predicted_probs_separate <- posterior_predict(thiomon_data_model_separate, newdata = test_data, draws = 1000, allow_new_levels = TRUE)
mean_probs_separate <- colMeans(predicted_probs_separate)

# ROC Curve
roc_curve_separate <- roc(test_data$remission, mean_probs_separate)
plot(roc_curve_separate, main = "ROC Curve for Separate Model")

# Confusion Matrix
predicted_classes_separate <- ifelse(mean_probs_separate >= optimal_threshold_separate$threshold, 1, 0)
conf_matrix_separate <- confusionMatrix(as.factor(predicted_classes_separate), as.factor(test_data$remission))
print(conf_matrix_separate)

#Report model summary, Rhat, ESS, convergence statistics etc.,
summary(thiomon_data_model_separate)

#Check EPLD LOO
loo(thiomon_data_model_separate)

#Check if chains converge
mcmc_trace(thiomon_data_model_separate, pars=c("b_hgb", "b_hct", "b_hbghctrat1", "b_hbghctrat2", "b_hbghctrat3", "b_hbghctrat4", "b_hbghctrat5")) + scale_colour_manual(values=c("#000000", "#E69F00", "#56B4E9", "#009E73"))

#Autocorrelation function?

#Make PP checks
pp_check(thiomon_data_model_separate, type='dens_overlay', ndraws=200)
pp_check(thiomon_data_model_separate, type='loo_pit_qq', ndraws=1000)
pp_check(thiomon_data_model_separate, type='pit_ecdf', ndraws=1000)

#Test for prior sensitivity
model_draws <- as_draws_df(thiomon_data_model_separate)

#Prior sensitivity is not there thanks to informative priors
# powerscale_plot_dens(model_draws, fit=thiomon_data_model_separate, help_text=FALSE)

#Also the values look good!
# powerscale_sensitivity(model_draws, fit=thiomon_data_model_separate) |> tt()

#Summarize the draws
model_draws |> subset_draws(variable=c('lprior','lp__'), exclude=TRUE) |> summarise_draws() |> tt()

as_draws_df(model_draws) |> mcmc_areas(pars=c("b_hgb", "b_hct", "b_hbghctrat1", "b_hbghctrat2", "b_hbghctrat3", "b_hbghctrat4", "b_hbghctrat5"))
```

```{r}
# Calculate predicted probabilities on training data
train_predicted_probs_hierarchical <- posterior_predict(thiomon_data_model_hier, newdata = train_data, draws = 4000, allow_new_levels = TRUE)
train_mean_probs_hierarchical <- colMeans(train_predicted_probs_hierarchical)

# Find optimal threshold using ROC curve on training data
train_roc_curve_hierarchical <- roc(train_data$remission, train_mean_probs_hierarchical)
optimal_threshold_hierarchical <- coords(train_roc_curve_hierarchical, "best", ret = "threshold")

# Predict on test data
predicted_probs_hierarchical <- posterior_predict(thiomon_data_model_hier, newdata = test_data, draws = 1000, allow_new_levels = TRUE)
mean_probs_hierarchical <- colMeans(predicted_probs_hierarchical)

# ROC Curve
roc_curve_hierarchical <- roc(test_data$remission, mean_probs_hierarchical)
plot(roc_curve_hierarchical, main = "ROC Curve for First Model")

# Confusion Matrix
predicted_classes_hierarchical <- ifelse(mean_probs_hierarchical >= optimal_threshold_hierarchical$threshold, 1, 0)
conf_matrix_hierarchical <- confusionMatrix(as.factor(predicted_classes_hierarchical), as.factor(test_data$remission))
print(conf_matrix_hierarchical)

# Report model summary, Rhat, ESS, convergence statistics etc.
summary(thiomon_data_model_hier)

# Check EPLD LOO
loo(thiomon_data_model_hier)

# Check if chains converge
mcmc_trace(thiomon_data_model_hier, pars=c("b_hgb", "b_hct", "sd_hbghctrat__Intercept", "r_hbghctrat[1,Intercept]", "r_hbghctrat[2,Intercept]","r_hbghctrat[3,Intercept]","r_hbghctrat[4,Intercept]","r_hbghctrat[5,Intercept]")) + scale_colour_manual(values=c("#000000", "#E69F00", "#56B4E9", "#009E73"))

# Autocorrelation function?

# Make PP checks
pp_check(thiomon_data_model_hier, type='dens_overlay', ndraws=200)
pp_check(thiomon_data_model_hier, type='loo_pit_qq', ndraws=1000)
pp_check(thiomon_data_model_hier, type='pit_ecdf', ndraws=1000)

# Test for prior sensitivity
model_draws_hierarchical <- as_draws_df(thiomon_data_model_hier)

# Prior sensitivity is not there thanks to informative priors
powerscale_plot_dens(model_draws_hierarchical, fit=thiomon_data_model_hier, help_text=FALSE)

# Also the values look good!
powerscale_sensitivity(model_draws_hierarchical, fit=thiomon_data_model_hier) |>
  tt()

# Summarize the draws
model_draws_hierarchical |> subset_draws(variable=c('lprior','lp__'), exclude=TRUE) |> summarise_draws() |> tt()

as_draws_df(model_draws_hierarchical) |> mcmc_areas(pars=c("b_hgb", "b_hct", "sd_hbghctrat__Intercept", "r_hbghctrat[1,Intercept]", "r_hbghctrat[2,Intercept]","r_hbghctrat[3,Intercept]","r_hbghctrat[4,Intercept]","r_hbghctrat[5,Intercept]"))
```
```{r}
loo_compare(loo(thiomon_data_model_pooled), loo(thiomon_data_model_separate), loo(thiomon_data_model_hier)) |>
  as.data.frame() |>
  rownames_to_column("model") |>
  dplyr::select(model, elpd_diff, se_diff) |>
  tt()
```


```{r}
if (!require(patchwork)) {
  install.packages("patchwork")
  library(patchwork)
}

#model_draws <- as_draws_df(thiomon_data_model_hier)
ph <- thiomon_data_model_hier |>
  spread_rvars(b_hgb, b_hct, r_hbghctrat[hbghctrat,]) |>
  mutate(mean_value = b_hgb + b_hct + r_hbghctrat) |>
  ggplot(aes(xdist= 1/(1+exp(-mean_value)), y=hbghctrat)) +
  stat_halfeye() +
  scale_y_continuous(breaks=1:5) +
  labs(x='Remission factor', y='hgb/hct Ratio', title='Hierarchical')

ps_part <- thiomon_data_model_separate |> 
  spread_rvars(b_hgb, b_hct)

ps_part_fin <- ps_part[rep(1:nrow(ps_part), each = 5), ]

ps <- thiomon_data_model_separate |>
  as_draws_df() |>
  subset_draws(variable = "b_hbghctrat", regex = TRUE) |>
  set_variables(paste0('b_hbghctrat[', 1:5, ']')) |>
  as_draws_rvars() |>
  spread_rvars(b_hbghctrat[hbghctrat]) |> cbind(ps_part_fin) |>
  mutate(mean_value = b_hbghctrat + b_hgb + b_hct) |>
  ggplot(aes(xdist=1/(1+exp(-mean_value)), y=hbghctrat)) +
  stat_halfeye() +
  scale_y_continuous(breaks=1:5) +
  labs(x='Remission factor', y='hgb/hct Ratio', title='Separate')

pp <- thiomon_data_model_pooled |>
  spread_rvars(b_Intercept) |>
  mutate(mean_value = b_Intercept) |>
  ggplot(aes(xdist=1/(1+exp(-mean_value)), y=0)) +
  stat_halfeye() +
  scale_y_continuous(breaks=NULL) +
  labs(x='Remission factor', y='Across all', title='Pooled model')

(ph / ps / pp) * xlim(c(0.0,1.0))
```





```{r}
library(e1071)
library(caret)

model_svm <- svm(remission ~ 0 + days_of_life + wbc + hgb + hct + plt + rbc + mcv + mch + mchc + rdw + mpv + neut_percent + lymph_percent + mono_percent + eos_percent + baso_percent + sod + pot + chlor + co2 + un + creat + gluc + cal + prot + alb + ast + alt + alk + tbil, data = train_data)


# Predict probabilities on the training data
pred_probs_svm <- predict(model_svm, train_data, probability = TRUE)

# Generate the ROC curve
train_roc_curve_svm <- roc(train_data$remission, pred_probs_svm)

# Find the optimal threshold
optimal_threshold_svm <- coords(train_roc_curve_svm, "best", ret = "threshold")

# Apply the threshold to the test_data find

# probs in test_data
pred_probs_svm_test <- predict(model_svm, test_data, probability = TRUE)
# Confusion matrix using the optimal_threshold_svm
pred_classes_svm <- ifelse(pred_probs_svm > optimal_threshold_svm$threshold, 1, 0)
conf_matrix_svm <- confusionMatrix(as.factor(pred_classes_svm), as.factor(train_data$remission))
print(conf_matrix_svm)

# Predict probabilities on the test data
pred_probs_svm_test <- predict(model_svm, test_data, probability = TRUE)
roc_curve_svm <- roc(test_data$remission, pred_probs_svm_test)

# Plot the ROC curve
plot(roc_curve_svm, main = "ROC Curve for SVM Model")
```

```{r}
model_glm <- glm(remission ~ 0 + days_of_life + wbc + hgb + hct + plt + rbc + mcv + mch + mchc + rdw + mpv + neut_percent + lymph_percent + mono_percent + eos_percent + baso_percent + sod + pot + chlor + co2 + un + creat + gluc + cal + prot + alb + ast + alt + alk + tbil, data = thiomon)

# Predict probabilities on the training data
pred_probs_glm <- predict(model_glm, train_data, type = "response")

# Generate the ROC curve
train_roc_curve_glm <- roc(train_data$remission, pred_probs_glm)

# Find the optimal threshold
optimal_threshold_glm <- coords(train_roc_curve_glm, "best", ret = "threshold")

# Apply the threshold to the test_data find

# probs in test_data
pred_probs_glm_test <- predict(model_glm, test_data, type = "response") 
# Confusion matrix using the optimal_threshold_glm

pred_classes_glm <- ifelse(pred_probs_glm > optimal_threshold_glm$threshold, 1, 0)
conf_matrix_glm <- confusionMatrix(as.factor(pred_classes_glm), as.factor(train_data$remission))
print(conf_matrix_glm)

# Predict probabilities on the test data
pred_probs_glm_test <- predict(model_glm, test_data, type = "response")
roc_curve_glm <- roc(test_data$remission, pred_probs_glm_test)

# Plot the ROC curve
plot(roc_curve_glm, main = "ROC Curve for GLM Model")
```

```{r}

model <- nnet(remission ~ days_of_life + wbc + hgb + hct + plt + rbc + mcv + mch + mchc + rdw + mpv + neut_percent + lymph_percent + mono_percent + eos_percent + baso_percent + sod + pot + chlor + co2 + un + creat + gluc + cal + prot + alb + ast + alt + alk + tbil, data = thiomon, size = 20,    # Number of hidden units 
maxit = 100)  # For classification

# Predict probabilities on the training data
pred_probs_nn <- predict(model, train_data, type = "raw")

# Generate the ROC curve
train_roc_curve_nn <- roc(train_data$remission, pred_probs_nn)

# Find the optimal threshold
optimal_threshold_nn <- coords(train_roc_curve_nn, "best", ret = "threshold")

# Apply the threshold to the training data
# pred_classes_glm <- ifelse(pred_probs_glm > optimal_threshold_glm$threshold, 1, 0)
pred_classes_nn <- ifelse(pred_probs_nn > optimal_threshold_nn$threshold, 1, 0)
conf_matrix_nn <- confusionMatrix(as.factor(pred_classes_nn), as.factor(train_data$remission))
print(conf_matrix_nn)

# Predict probabilities on the test data
pred_probs_nn_test <- predict(model, test_data, type = "raw")

# Apply the threshold to the test data
pred_classes_nn_test <- ifelse(pred_probs_nn_test > optimal_threshold_nn$threshold, 1, 0)
conf_matrix_nn_test <- confusionMatrix(as.factor(pred_classes_nn_test), as.factor(test_data$remission))
print(conf_matrix_nn_test)

# Generate the ROC curve
roc_curve_nn <- roc(test_data$remission, pred_probs_nn_test)

# Plot the ROC curve
plot(roc_curve_nn, main = "ROC Curve for Neural Network Model")
```

```{r}
library(pROC)
library(ggplot2)

# Function to interpolate and smooth ROC curve with jitter
interpolate_smooth_roc_jitter <- function(roc_curve, n = 100, jitter_amount = 1e-5) {
  roc_smooth <- smooth(roc_curve)
  fpr <- seq(0, 1, length.out = n)
  tpr <- approx(roc_smooth$specificities + runif(length(roc_smooth$specificities), -jitter_amount, jitter_amount), 
                roc_smooth$sensitivities, xout = fpr)$y
  data.frame(fpr = fpr, tpr = tpr)
}

# Calculate and interpolate ROC curves with jitter
roc_pooled_train <- interpolate_smooth_roc_jitter(train_roc_curve_pooled)
roc_pooled_test <- interpolate_smooth_roc_jitter(roc_curve_pooled)
roc_separate_train <- interpolate_smooth_roc_jitter(train_roc_curve_separate)
roc_separate_test <- interpolate_smooth_roc_jitter(roc_curve_separate)
roc_hierarchical_train <- interpolate_smooth_roc_jitter(train_roc_curve_hierarchical)
roc_hierarchical_test <- interpolate_smooth_roc_jitter(roc_curve_hierarchical)
# glm, svm and nn model too
roc_glm_train <- interpolate_smooth_roc_jitter(train_roc_curve_glm)
roc_glm_test <- interpolate_smooth_roc_jitter(roc_curve_glm)
roc_svm_train <- interpolate_smooth_roc_jitter(train_roc_curve_svm)
roc_svm_test <- interpolate_smooth_roc_jitter(roc_curve_svm)
roc_nn_train <- interpolate_smooth_roc_jitter(train_roc_curve_nn)
roc_nn_test <- interpolate_smooth_roc_jitter(roc_curve_nn)

# Calculate AUC values
auc_pooled_train <- auc(train_roc_curve_pooled)
auc_pooled_test <- auc(roc_curve_pooled)
auc_separate_train <- auc(train_roc_curve_separate)
auc_separate_test <- auc(roc_curve_separate)
auc_hierarchical_train <- auc(train_roc_curve_hierarchical)
auc_hierarchical_test <- auc(roc_curve_hierarchical)
auc_glm_train <- auc(train_roc_curve_glm)
auc_glm_test <- auc(roc_curve_glm)
auc_svm_train <- auc(train_roc_curve_svm)
auc_svm_test <- auc(roc_curve_svm)
auc_nn_train <- auc(train_roc_curve_nn)
auc_nn_test <- auc(roc_curve_nn)

# Combine ROC curves into one data frame
roc_data <- rbind(
  data.frame(roc_pooled_train, model = paste("Pool Train (AUC =", round(auc_pooled_train, 4), ")")),
  data.frame(roc_pooled_test, model = paste("Pool Test (AUC =", round(auc_pooled_test, 4), ")")),
  data.frame(roc_separate_train, model = paste("Separate Train (AUC =", round(auc_separate_train, 4), ")")),
  data.frame(roc_separate_test, model = paste("Separate Test (AUC =", round(auc_separate_test, 4), ")")),
  data.frame(roc_hierarchical_train, model = paste("Hierarchical 1 Train (AUC =", round(auc_hierarchical_train, 4), ")")),
  data.frame(roc_hierarchical_test, model = paste("Hierarchical 1 Test (AUC =", round(auc_hierarchical_test, 4), ")")),
  data.frame(roc_glm_train, model = paste("GLM Train (AUC =", round(auc_glm_train, 4), ")")),
  data.frame(roc_glm_test, model = paste("GLM Test (AUC =", round(auc_glm_test, 4), ")")),
  data.frame(roc_svm_train, model = paste("SVM Train (AUC =", round(auc_svm_train, 4), ")")),
  data.frame(roc_svm_test, model = paste("SVM Test (AUC =", round(auc_svm_test, 4), ")")),
  data.frame(roc_nn_train, model = paste("NN Train (AUC =", round(auc_nn_train, 4), ")")),
  data.frame(roc_nn_test, model = paste("NN Test (AUC =", round(auc_nn_test, 4), ")"))
  )

# Plot all ROC curves in one plot
ggplot(roc_data, aes(x = fpr, y = tpr, color = model)) +
  geom_line() +
  labs(title = "ROC Curves for Different Models", x = "False Positive Rate", y = "True Positive Rate") +
  theme_minimal()
```